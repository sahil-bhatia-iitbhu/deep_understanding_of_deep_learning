{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNl4kUCjzNlS782U2jl0se+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahil-bhatia-iitbhu/deep_understanding_of_deep_learning/blob/main/01_maths.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep Learning is SIMPLE, COMPLICATED and COMPLEX at the same time.\n",
        "\n",
        "SIMPLE : The underlying maths is simple, linear algebra and probability\n",
        "\n",
        "COMPLICATED : It contains many parts (neurons)\n",
        "\n",
        "COMPLEX : It contains many nonlinear functions, and it is unintuitive and difficult to understand"
      ],
      "metadata": {
        "id": "yIStEnWweIuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Types in terms of numbers\n",
        "\n",
        "1. Scalar\n",
        "\n",
        "2. Vector\n",
        "\n",
        "3. Matrix\n",
        "\n",
        "4. Tensors"
      ],
      "metadata": {
        "id": "QacxuSxhe6h9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reality is attempted to present in deep learning in the form of 2 variables,\n",
        "1. Continous Variables\n",
        "2. Categorical Variables\n",
        "\n",
        "The non-numeric categorical variables are presented through dummy-coding (numeric tagging of each category to a number), and the extention to it is one-hot encoding (variable for each category with 1/0 flag)"
      ],
      "metadata": {
        "id": "oWoLpIMSfQQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transposing a matrix"
      ],
      "metadata": {
        "id": "fhs8sP_ajVcC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kl8TDPwdyaLD"
      },
      "outputs": [],
      "source": [
        "# import library\n",
        "\n",
        "import numpy as np\n",
        "import torch as t"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a vector\n",
        "nv = np.array([[1,2,3,4,5]])\n",
        "print(f\"vector: \\n\",nv), print(f\" \")\n",
        "print(f\"transpose: \\n\",nv.T), print(f\" \")\n",
        "\n",
        "nvT = nv.T\n",
        "print(f\"transpose of transpose: \\n\",nvT.T), print(f\" \")\n",
        "\n",
        "print(f\"Variable nv is of type: {type(nv)}\")"
      ],
      "metadata": {
        "id": "Y2g_OzKMjfqp",
        "outputId": "d835ec6b-7776-4097-af11-73eea1d73d09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vector: \n",
            " [[1 2 3 4 5]]\n",
            " \n",
            "transpose: \n",
            " [[1]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [5]]\n",
            " \n",
            "transpose of transpose: \n",
            " [[1 2 3 4 5]]\n",
            " \n",
            "Variable nv is of type: <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a matrix\n",
        "nv = np.array([[1,2,3,4,5],[6,7,8,9,0]])\n",
        "print(f\"vector: \\n\",nv), print(f\" \")\n",
        "print(f\"transpose: \\n\",nv.T), print(f\" \")\n",
        "\n",
        "nvT = nv.T\n",
        "print(f\"transpose of transpose: \\n\",nvT.T), print(f\" \")\n",
        "\n",
        "print(f\"Variable nv is of type: {type(nv)}\")"
      ],
      "metadata": {
        "id": "-5ZkEtXwmEtO",
        "outputId": "0a5ec808-d78b-47e9-f0a1-ee1fee2f15f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vector: \n",
            " [[1 2 3 4 5]\n",
            " [6 7 8 9 0]]\n",
            " \n",
            "transpose: \n",
            " [[1 6]\n",
            " [2 7]\n",
            " [3 8]\n",
            " [4 9]\n",
            " [5 0]]\n",
            " \n",
            "transpose of transpose: \n",
            " [[1 2 3 4 5]\n",
            " [6 7 8 9 0]]\n",
            " \n",
            "Variable nv is of type: <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using PyTorch\n",
        "\n",
        "# create a vector\n",
        "nv = t.tensor([[1,2,3,4,5]])\n",
        "print(f\"vector: \\n\",nv), print(f\" \")\n",
        "print(f\"transpose: \\n\",nv.T), print(f\" \")\n",
        "\n",
        "nvT = nv.T\n",
        "print(f\"transpose of transpose: \\n\",nvT.T)\n",
        "\n",
        "print(f\"Variable nv is of type: {type(nv)}\")"
      ],
      "metadata": {
        "id": "Itn6KjMumJ9h",
        "outputId": "7df05abb-3601-4c27-c6c6-3f286f50e14e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vector: \n",
            " tensor([[1, 2, 3, 4, 5]])\n",
            " \n",
            "transpose: \n",
            " tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4],\n",
            "        [5]])\n",
            " \n",
            "transpose of transpose: \n",
            " tensor([[1, 2, 3, 4, 5]])\n",
            "Variable nv is of type: <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using PyTorch\n",
        "\n",
        "# create a vector\n",
        "nv = t.tensor([[1,2,3,4,5],[6,7,8,9,0]])\n",
        "print(f\"vector: \\n\",nv), print(f\" \")\n",
        "print(f\"transpose: \\n\",nv.T), print(f\" \")\n",
        "\n",
        "nvT = nv.T\n",
        "print(f\"transpose of transpose: \\n\",nvT.T)\n",
        "\n",
        "print(f\"\\nVariable nv is of type: {type(nv)}\")"
      ],
      "metadata": {
        "id": "DBz75Bf6mWnK",
        "outputId": "9db9e875-733a-43fb-a6e4-81e3e3ff0e4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vector: \n",
            " tensor([[1, 2, 3, 4, 5],\n",
            "        [6, 7, 8, 9, 0]])\n",
            " \n",
            "transpose: \n",
            " tensor([[1, 6],\n",
            "        [2, 7],\n",
            "        [3, 8],\n",
            "        [4, 9],\n",
            "        [5, 0]])\n",
            " \n",
            "transpose of transpose: \n",
            " tensor([[1, 2, 3, 4, 5],\n",
            "        [6, 7, 8, 9, 0]])\n",
            "\n",
            "Variable nv is of type: <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DNqcOZbvmn8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DOT PRODUCT\n",
        "\n",
        "Single number that represents the commonality between the 2 mathematical data type (matrix,tensor,vector,signal,images)"
      ],
      "metadata": {
        "id": "w9s5ztOSpLy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using numpy\n",
        "\n",
        "nv1 = np.array([1,2,3,4,5])\n",
        "nv2 = np.array([6,7,8,9,0])\n",
        "\n",
        "# using function\n",
        "dp = np.dot(nv1,nv2)\n",
        "print(f\"dot product: {dp}\")\n",
        "print(f\"Variable dp is of type: {type(dp)}\")\n",
        "\n",
        "# using computation\n",
        "dp = np.sum(nv1*nv2)\n",
        "print(f\"dot product: {dp}\")\n",
        "print(f\"Variable dp is of type: {type(dp)}\")\n",
        "print(f\"Shape of nv1: {nv1.shape}\")\n",
        "print(f\"Shape of nv2: {nv2.shape}\\n\")\n",
        "\n",
        "\n",
        "# try different dimensions\n",
        "\n",
        "nv1 = np.array([1,2,3,4,5])\n",
        "nv2 = np.array([6,7,8,9])\n",
        "\n",
        "try:\n",
        "  dp = np.dot(nv1,nv2)\n",
        "  print(f\"dot product: {dp}\")\n",
        "  print(f\"Variable dp is of type: {type(dp)}\")\n",
        "except ValueError as e:\n",
        "    print(\"Error:\", e)\n",
        "    print(f\"Shape of nv1: {nv1.shape}\")\n",
        "    print(f\"Shape of nv2: {nv2.shape}\")"
      ],
      "metadata": {
        "id": "Un4d8YkfpNzv",
        "outputId": "c85a5779-a94c-4dce-d86a-551294f5651f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot product: 80\n",
            "Variable dp is of type: <class 'numpy.int64'>\n",
            "dot product: 80\n",
            "Variable dp is of type: <class 'numpy.int64'>\n",
            "Shape of nv1: (5,)\n",
            "Shape of nv2: (5,)\n",
            "\n",
            "Error: shapes (5,) and (4,) not aligned: 5 (dim 0) != 4 (dim 0)\n",
            "Shape of nv1: (5,)\n",
            "Shape of nv2: (4,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using numpy\n",
        "\n",
        "nv1 = t.tensor([1,2,3,4,5])\n",
        "nv2 = t.tensor([6,7,8,9,0])\n",
        "\n",
        "# using function\n",
        "dp = t.dot(nv1,nv2)\n",
        "print(f\"dot product: {dp}\")\n",
        "print(f\"Variable dp is of type: {type(dp)}\")\n",
        "\n",
        "# using computation\n",
        "dp = t.sum(nv1*nv2)\n",
        "print(f\"dot product: {dp}\")\n",
        "print(f\"Variable dp is of type: {type(dp)}\")\n",
        "print(f\"Shape of nv1: {nv1.shape}\")\n",
        "print(f\"Shape of nv2: {nv2.shape}\\n\")\n",
        "\n",
        "\n",
        "# try different dimensions\n",
        "\n",
        "nv1 = t.tensor([1,2,3,4,5])\n",
        "nv2 = t.tensor([6,7,8,9])\n",
        "\n",
        "try:\n",
        "  dp = t.dot(nv1,nv2)\n",
        "  print(f\"dot product: {dp}\")\n",
        "  print(f\"Variable dp is of type: {type(dp)}\")\n",
        "except RuntimeError as e:\n",
        "    print(\"Error:\", e)\n",
        "    print(f\"Shape of nv1: {nv1.shape}\")\n",
        "    print(f\"Shape of nv2: {nv2.shape}\")"
      ],
      "metadata": {
        "id": "FtBsTnZrpkmr",
        "outputId": "30d85403-7b50-4b43-90f6-4e37487fc294",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot product: 80\n",
            "Variable dp is of type: <class 'torch.Tensor'>\n",
            "dot product: 80\n",
            "Variable dp is of type: <class 'torch.Tensor'>\n",
            "Shape of nv1: torch.Size([5])\n",
            "Shape of nv2: torch.Size([5])\n",
            "\n",
            "Error: inconsistent tensor size, expected tensor [5] and src [4] to have the same number of elements, but got 5 and 4 elements respectively\n",
            "Shape of nv1: torch.Size([5])\n",
            "Shape of nv2: torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3yQ9ZZPMrTeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix Multiplication\n",
        "\n",
        "AxB is only possible if columns of A are equal to rows of B"
      ],
      "metadata": {
        "id": "6Df9xAe6sJ9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Numpy\n",
        "\n",
        "A = np.random.randn(3,4)\n",
        "B = np.random.randn(4,5)\n",
        "C = np.random.randn(3,5)\n",
        "\n",
        "# try some multiplication\n",
        "print(f\"AxB:\")\n",
        "try:\n",
        "  print(np.round(A@B,2))\n",
        "except ValueError as e:\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "print(f\"BxC:\")\n",
        "try:\n",
        "  print(np.round(A@C,2))\n",
        "except ValueError as e:\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "print(f\"AxC:\")\n",
        "try:\n",
        "  print(np.round(A.T@C,2))\n",
        "except ValueError as e:\n",
        "    print(\"Error:\", e)\n"
      ],
      "metadata": {
        "id": "Y6bAOL31uHZi",
        "outputId": "1e7bbeef-112a-4bc6-8054-e06b77aa0619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AxB:\n",
            "[[-1.48  0.2   0.72  1.79 -0.16]\n",
            " [ 1.07  0.03 -0.71  1.91 -1.59]\n",
            " [-0.34 -0.26 -0.59  0.98  1.3 ]]\n",
            "BxC:\n",
            "Error: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 4)\n",
            "AxC:\n",
            "[[ 0.4   0.96  1.11 -0.44  0.2 ]\n",
            " [ 2.42  0.81  2.98  6.79  3.4 ]\n",
            " [ 0.88 -0.48 -0.06  2.81  1.45]\n",
            " [-0.7  -0.55 -0.29  0.26 -0.65]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Numpy\n",
        "\n",
        "A = t.randn(3,4)\n",
        "B = t.randn(4,5)\n",
        "C1 = np.random.randn(3,5)\n",
        "C2 = t.tensor(C1,dtype=t.float)\n",
        "\n",
        "# try some multiplication\n",
        "print(f\"AxB:\")\n",
        "try:\n",
        "  print(np.round(A@B,2))\n",
        "except RuntimeError as e:\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "print(f\"BxC2:\")\n",
        "try:\n",
        "  print(np.round(A@C,2))\n",
        "except RuntimeError as e:\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "print(f\"A.TxC1:\")\n",
        "try:\n",
        "  print(np.round(A.T@C,2))\n",
        "except RuntimeError as e:\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "print(f\"A.TxC2:\")\n",
        "try:\n",
        "  print(np.round(A.T@C,2))\n",
        "except RuntimeError as e:\n",
        "    print(\"Error:\", e)\n"
      ],
      "metadata": {
        "id": "HukQTT-PuwZ3",
        "outputId": "4f585fe6-7d93-40be-cfbe-cbc6f5278e30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AxB:\n",
            "tensor([[ 0.2500,  0.4200,  2.6600, -2.8400, -0.8300],\n",
            "        [ 1.4000, -0.1200,  0.8100,  1.4200,  1.6400],\n",
            "        [-1.4100,  0.4300,  0.2800, -1.9300, -1.8500]])\n",
            "BxC2:\n",
            "Error: mat1 and mat2 shapes cannot be multiplied (3x4 and 3x5)\n",
            "A.TxC1:\n",
            "tensor([[-0.2800,  1.5500,  0.7700, -0.6900,  0.7100],\n",
            "        [-0.1600, -2.2500, -0.1400, -0.0200, -0.9700],\n",
            "        [-1.5800, -2.0300,  1.9300, -1.6100, -2.2000],\n",
            "        [-2.3300, -4.9200,  2.2700, -1.5500, -4.9800]])\n",
            "A.TxC2:\n",
            "tensor([[-0.2800,  1.5500,  0.7700, -0.6900,  0.7100],\n",
            "        [-0.1600, -2.2500, -0.1400, -0.0200, -0.9700],\n",
            "        [-1.5800, -2.0300,  1.9300, -1.6100, -2.2000],\n",
            "        [-2.3300, -4.9200,  2.2700, -1.5500, -4.9800]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5nh_Q7sTvdmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Softmax\n",
        "\n",
        "The softmax function converts raw prediction scores (logits) from a neural network into a probability distribution. For a vector of logits $z=[z_1,z_2,...,z_K]$, softmax is mathematically defined as: [geeksforgeeks](https://www.geeksforgeeks.org/deep-learning/the-role-of-softmax-in-neural-networks-detailed-explanation-and-applications/)\n",
        "\n",
        "$Softmax(z_i)=\\frac{e^{z_i}}{∑_{j=1}^Ke^{z_j}}$\n",
        "\n",
        "The exponential in the numerator ensures all outputs are positive, while the denominator normalizes them so probabilities sum to 1. This works with any real-valued logits—positive, negative, or zero. [deepai](https://deepai.org/machine-learning-glossary-and-terms/softmax-layer)"
      ],
      "metadata": {
        "id": "m7YxGs0pAWtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "\n",
        "import numpy as np\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings"
      ],
      "metadata": {
        "id": "Pj0WH9ESAjtm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# manually in numpy\n",
        "\n",
        "z = [1,2,3]\n",
        "\n",
        "num = np.exp(z)\n",
        "den = np.sum(np.exp(z))\n",
        "softmax = num/den\n",
        "\n",
        "print(f\"Softmax of z: {softmax}\")\n",
        "print(f\"Sum of Softmax of z: {np.sum(softmax)}\")"
      ],
      "metadata": {
        "id": "oiIqEVgmA0yp",
        "outputId": "d51e5c65-a934-4e7a-877c-5c104dbe5c77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax of z: [0.09003057 0.24472847 0.66524096]\n",
            "Sum of Softmax of z: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# manually in numpy\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "z = np.random.randint(-25,25,size=10)\n",
        "print(f\"z: {z}\")\n",
        "\n",
        "num = np.exp(z)\n",
        "den = np.sum(np.exp(z))\n",
        "softmax = num/den\n",
        "\n",
        "print(f\"Softmax of z: {np.round(softmax,3)}\")\n",
        "print(f\"Sum of Softmax of z: {np.round(np.sum(softmax),0)}\")\n",
        "\n",
        "# compare\n",
        "plt.plot(z,softmax,'ko')\n",
        "plt.xlabel(\"Original Number (z)\")\n",
        "plt.ylabel(\"Softmax $\\sigma$\")\n",
        "# plt.yscale('log')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A0PXAzfzBvYw",
        "outputId": "c5a00b1a-1a7b-4815-e8ba-6519e4f8b431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "z: [  3  11   1 -25  -5 -23  19   8  -5  22]\n",
            "Softmax of z: [0.    0.    0.    0.    0.    0.    0.047 0.    0.    0.953]\n",
            "Sum of Softmax of z: 1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "softfun = nn.Softmax(dim=0)\n",
        "softmaxT = softfun(t.tensor(z).float())\n",
        "\n",
        "print(f\"Softmax of z: {softmaxT.round(decimals=3)}\")\n",
        "print(f\"Sum of Softmax of z: {softmaxT.sum().round(decimals=0)}\")"
      ],
      "metadata": {
        "id": "LygHHu29Cp4x",
        "outputId": "7ee13f1a-13f6-4362-b65e-33b5024c6bf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax of z: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0470, 0.0000, 0.0000,\n",
            "        0.9530])\n",
            "Sum of Softmax of z: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r1zF1m_lEtXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Log Function\n",
        "\n",
        "Why log function is preferred in a loss function?\n",
        "    \n",
        "1. **Numerical Stability:** Log functions prevent **overflow and underflow issues** common in deep learning. Without logs, computing products of small probabilities (e.g., 0.001×0.002×0.00010.001×0.002×0.0001) underflows to zero. The logarithm converts products to sums:  log⁡(p1×p2×p3)=log⁡(p1)+log⁡(p2)+log⁡(p3), maintaining numerical precision. Computing loss from logits (raw model outputs) before applying softmax further improves stability by avoiding intermediate probability calculations that can overflow\n",
        "\n",
        "2. **Lower Values give Higher Differences:** The closer the log function gets to input zero, it gives bigger jumps to small movements which helps during training when improvements comes down in last stages where improvements are marginal or loss are small\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0gcv_D0fM4-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qm-Mb0FVNiFs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}