{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMU6zQe78i4JGvmtr3zY4o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahil-bhatia-iitbhu/deep_understanding_of_deep_learning/blob/main/17_Style_Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Style Transfer"
      ],
      "metadata": {
        "id": "stcjI-jK65_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The feature maps of the existing pretrained model are accessed, but not the its true mapping of features, but the related styling using concept of gram matrices."
      ],
      "metadata": {
        "id": "aA_6UAob69at"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gram Matrices:\n",
        "- The concept is driven from the covariance matrix concept, where we get the pairwise interactions between the features.\n",
        "- Covariance matrix represents the patterns distributed across the featuresm not the indivisual features.\n",
        "- In style transfer, the feature covariance matrix encodes a higher-level feature-interaction space; a combination of many features.\n",
        "- Gram matrix is cross product of feature maps with itself to capture the patterns captured by all feature maps combined, and avoids deep training data specific patterns. Hence, only picking the style.\n",
        "\n",
        "**Note:** The 3D feature maps are converted into the 2D maps as below:\n",
        "\n",
        "Height x Width x Channels --> Channels x (Width*Height)"
      ],
      "metadata": {
        "id": "BeFZVEGf7ea6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Style Transfer Algorithm**\n",
        "\n",
        "1. Model is frozen, the image is trained. Prefer pretrained models trained on big datasets\n",
        "2. Import and transform images\n",
        "3. Match Content (\"pixel-level\" feature mapping): Prefer to use the early layers of the pretrained model to capture the style, and not the true image identities that are generally present in the built up layers.\n",
        "\n",
        "- Loss Function : $\\sum(Content Image - Target Image)^2$\n",
        "\n",
        "4. Match Style (\"texture-level\" feature mapping): Here, GRAM MATRICES from different frozen layers are used and compared to Gram Matrices of Target.\n",
        "\n",
        "- Loss Function : $\\sum(Style Gram - Target Gram)^2$"
      ],
      "metadata": {
        "id": "-U4hI_WzAZpZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzV3kJt6aVwS"
      },
      "outputs": [],
      "source": []
    }
  ]
}